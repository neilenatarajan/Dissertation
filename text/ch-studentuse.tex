% \begin{savequote}[8cm]
% Alles Gescheite ist schon gedacht worden.\\
% Man muss nur versuchen, es noch einmal zu denken.

% All intelligent thoughts have already been thought;\\
% what is necessary is only to try to think them again.
%   \qauthor{--- Johann Wolfgang von Goethe \cite{von_goethe_wilhelm_1829}}
% \end{savequote}

\chapter{\label{ch:studentuse}Student Generative AI Usage in Application Essays [WIP]}

\minitoc

\section{Introduction}
To-do

\section{Detecting Generative AI Usage in Application Essays} % Slightly worried about this. It's narrative fit with ch4 isn't as strong as the others. It's not a cohort-type issue here. It's also not "identifying talent" in the way the other two are. Does this get its own chapter? Maybe this goes after the IAI bit. Then it's something like "we've talked about TI people using AI, but an obvious shift in TI is being caused by students using AI. We need to understand how to detect this / what it means. The student use here might threaten everything else we've done, and we need to scope the problem."
%Alt: if xAI filtering and CV screening becomes the norm, can applicants game this? Can you produce outputs such that the determinations favour you in some way?
Student use of generative AI in essay-writing creates new challenges for education in the marking of essays and essay-based selection for scholarships, fellowships, and universities. In theory, software purporting to detect AI-generated content can act as a post-hoc explanation of generated content, and thus offers a plausible solution to educators inquiring about the use of generative AI in student essays. In practice, little research has attempted to validate such solutions in real-world situations or to examine their limitations. We present an empirical case study exploring the efficacy and implications of using one such detection product, GPTZero, in the selection process for a program looking for talented young people from around the world. We observe that GPTZero does not perform sufficiently well for the program to disqualify applicants on its basis alone. Also, GPTZero's scores are heterogeneously biased across geographical and gender groups. However, we find GPTZero accurate enough to conduct useful aggregate analyses of potential vulnerability to AI-enabled attacks on the integrity of the program's application process. We find evidence for only limited use of AI-generated text in the program's latest application cycle and no evidence partner organizations used AI-generated text at scale to defraud the program's referral program.

(To-do)
