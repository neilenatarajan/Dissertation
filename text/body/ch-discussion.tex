% \begin{savequote}[8cm]
% Alles Gescheite ist schon gedacht worden.\\
% Man muss nur versuchen, es noch einmal zu denken.

% All intelligent thoughts have already been thought;\\
% what is necessary is only to try to think them again.
%   \qauthor{--- Johann Wolfgang von Goethe \cite{von_goethe_wilhelm_1829}}
% \end{savequote}

\chapter{\label{ch:discussion}Discussion}

\minitoc

\section{Selection-Oriented AI}
In this thesis, we explore the role of AI systems as Decision Support Tools (DSTs) in talent identification. We find that existing AI systems often fail to meet the needs of selection practitioners, particularly for in-process decision-making. In response, we propose a new paradigm, Selection-Oriented AI (SOAI). While present human-centric paradigms see stakeholders as the centres of design efforts, the problem of selecting talent doesn't lend itself to this framing. In addition to the selection organisation, interested in selecting the best cohort they can, and the applicants, interested in being selected, society at large has interest in the outcomes of selection processes. In particular, social values such as fairness, diversity, integrity, justice, etc. should be upheld. In building tools with selection practitioners as the centre of design, we risk neglecting these broader social values. SOAI seeks to address this by centering the design of AI systems around the social values that selection processes should uphold; while this involves designing around the people making selection decisions, it does not end with their satisfaction. Rather, it requires evaluations of the social impact of selection processes and the tools that support them.

\section{Design Recommendations for SOAI Designers}
\subsection{Design for Specific Social Values}
While we wish to design to support all social values in the selection process, Chapter \ref{ch:diversity} demonstrates the difficulty of unpacking the social value of diversity, and we find success instead focusing on smaller component values that comprise diversity. We suggest this generalises to SOAI practices in general. Rather than designing around myriad values, only to find conflicting design implications of these disparate values, designers seeking to support social values in selection processes should focus on specific social values worthy of consideration.

\subsection{Identify Decision Points with the Decision Matrix}
In Chapter \ref{ch:context}, we conceive of selection as a series of decisions. We introduce the Decision Matrix framework to categorise the many decision points that selection practitioners face according to their two most germane axes: the stakes of the decision and its stage in selection. This framework allows designers to evaluate the suitability of AI systems as DSTs for groups of related decision points by determining desired properties for quadrants of the Decision Matrix, then designing for and evaluating those properties. We recommend that designers use the Decision Matrix to identify the decision points relevant to their context and evaluate the suitability of AI systems as DSTs for those points, but to be cautious, as the Decision Matrix framework provides a necessary, but perhaps not sufficient, set of properties. 

\subsection{Balance Quantitative and Qualitative Information in Presentation}
Human decision-makers often desire both a qualitative understanding of applicants and quantitative metrics to compare them. In Chapters \ref{ch:xai} and \ref{ch:diversity}, we find that selection practitioners from programs A and B seek to make decisions informed by both kinds of information; despite this, the desired balance between these modes of information varies based both on practitioner and type of decision. When quantitative information is neglected, practitioners are forced to make decisions on a case-by-case basis without important numerical context comparing applicants to a larger group; when qualitative information is neglected, practitioners are unable to consider applicants holistically. Developers following SOAI should consider the balance between quantitative and qualitative information in their systems, and design their systems to provide both when necessary.

\subsection{Evaluate Real Change in Addition to Subjective Satisfaction}
\textcite{Lipton} critiques explainable AI (xAI) systems on the grounds that they risk satisfying the subjective desires of the users while failing to improve objective outcomes. In Chapter \ref{ch:xai}, we confirm that this critique applies to some post-hoc justifications of model recommendations, as the justifications were found to yield an unwarranted increase in trust in the human decision-makers. Thus, it is important to define and evaluate measures of the social values that DSTs intend to support; when evaluating these DSTs, they should not be evaluated human-centrically (i.e., according to their users' satisfaction), but should instead be evaluated on whether their employment improves social outcomes.

\section{Limitations and Future Work}
While quantitative analyses were performed on a variety of participants from program applicants to Prolific members, our qualitative analyses were limited to a small number of selection practitioners from only two programs. While these programs are leaders in the global talent selection context, findings applied to these two programs may not apply directly to other programs. Additionally, while SOAI is likely applicable to related selection contexts such as university selection or job hiring, further research is needed to explore the limits of its generalisability.

We deliberately do not engage applicants in our process. In general, \textcite{citation needed} contend that human-centred design should consider the positions of all stakeholders. More specifically, \textcite{venn-wycherley_realities_2024} argue that human-centred research in a classroom setting should consider both educators and students. Unlike other scenarios, though, applicant and selection practitioner organisation incentives conflict; and while most HCI contexts would see a need to balance these groups' needs in designing for the space, we conclude that the social aims of the selection problem itself supersede both groups. As selection practitioners most often find themselves aligned to these social aims, we focus on them. Future work should seek to engage applicants in this context. That said, work exploring the perspectives of applicants should consider first the value and ultimate aim of selection.

Much of our work depends on the contested assumption that global selection processes further societal interests, and that thus supporting the selection process improves social outcomes. \textcite{Warikoo_2019} critiques diversity in elite institutions on the grounds that it merely serves to maintain the status quo. We have contended in Chapter \ref{ch:diversity} that, due to the global talent search's broad reach and engagement with people from a truly diverse set of backgrounds, this critique does not apply here. If it does apply here, the implications for SOAI would be dire. Future work should explore the relationship between selection processes and social outcomes, particularly in the context of diversity.

\section{Conclusion}
In this thesis, we pioneer a new paradigm of AI design for selection processes, Selection-Oriented AI (SOAI). Chapters \ref{ch:xai} and \ref{ch:genai} find that existing AI systems often fail to meet the needs of selection practitioners, particularly for in-process decision-making. In response, we propose a new paradigm, SOAI, which seeks to centre the design of AI DSTs not around the selection practitioners but around the social aims of selection they seek to practice. Chapters \ref{ch:diversity} and \ref{ch:spf} apply SOAI principles to design DSTs to support considerations of diversity in selection; we implement a prototype designed to satisfy selection practitioner desires and find that it improves both diversity and performance outcomes in selection. We then provide a set of design recommendations for SOAI designers, including focusing on specific social values, identifying decision points with the Decision Matrix, balancing quantitative and qualitative information, and evaluating real change in addition to subjective satisfaction. We conclude with a call for more selection-oriented work, applying data-driven support to this difficult and sensitive problem.