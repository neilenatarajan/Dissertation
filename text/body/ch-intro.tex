% \begin{savequote}[8cm]
% \textlatin{Neque porro quisquam est qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit...}

% There is no one who loves pain itself, who seeks after it and wants to have it, simply because it is pain...
%   \qauthor{--- Cicero's \textit{de Finibus Bonorum et Malorum}}
% \end{savequote}

\chapter{\label{ch:intro}Introduction} 

\minitoc

% To-do: rewrite

Since early theorising about Artificial Intelligence (AI), experts have noted the transformative potential of such technology. Now, with the popular advent of Machine Learning (ML) models and transformer architecture in particular, we see rapid mass-market adoption of a variety of AI tools. In many fields which deal with sensitive decision-making, this adoption introduces new ethical challenges. In the fields of talent and Talent Identification (TI) in particular, many of these ethical challenges centre on decision tool interpretability; diversity, equity, and inclusion (DEI); and applicant usage of generative AI. In this section, we lay out the case for the application of AI systems (specifically interpretable AI decision assistants) to these issues in TI, paying special attention to the potential pitfalls and broader implications of our proposal.

\section{A Brief Account of Talent Identification, its Adoption of Artificial Intelligence, and Challenges Arising}
(To-do)
% Intro needs a sociological account of talent identification. What is it? How does it differ from recruitment? What niche within TI do I focus on? I talk about this a bit in the organisation discussion but should go into greater detail here.

\section{Motivation}
(To-do) This is where I explain why I'm doing this research. I explain why care about talent identification and how IAIDSTs can solve problems here. I respond to the notion that we should simply not use AI here, and highlight problems in the field already. I explain why this is a problem for Computer Science as well as for Talent Science (tl;dr: additional reasons to care about things xai overlooks because of the application domain)

\section{Contributions}
In this thesis, we make a number of theoretical, technical and practical contributions. These are:

\begin{itemize}
    \item We articulate where talent identification experts should use IAIDSTs to assist in their decision-making, and which IAI systems are appropriate for which purposes
    \item We apply research-through-design methods to talent identification to produce a novel approach to the creation of human-centric selection tooling
    \item We develop a novel method for visualising and understanding cohort-level decisions surrounding diversity called the Selection Possibility Frontier
    \item We further implement a novel algorithm for approximating the Selection Possibility Frontier
    \item We produce several qualitative, quantitative, and mixed-modal datasets relating to talent identification
    \item We demonstrate a yet-undemonstrated risk associated with naive application of post-hoc explainability to a range of problems
    \item We demonstrate the utility and limitation of detection tools for generative-AI-written essays in a scholarship context, and explore implications for scholarship programs
\end{itemize}

\section{Thesis Structure}
In this chapter, we explore our motivation for focusing on the application of IAIDSTs to talent identification, enumerate our contributions, and provide an account of challenges talent identification. Among these challenges, we focus the remainder of this thesis on three: limited human understanding of the AI tools, limited ability to consider diversity, and the risks of applicant usage of generative AI.

In Chapter \ref{ch:background}, we provide a background on the field of talent identification, the field of explainable AI, and the field of diversity, equity, and inclusion; we further explore intersections between these fields of research and identify gaps in the literature. Chapters \ref{ch:xailimitations} and \ref{ch:usingxai} explore our first challenge: limited human understanding of the AI tools. In Chapter \ref{ch:xailimitations}, we explore the limitations of popular xAI methods in the context of talent identification. In Chapter \ref{ch:usingxai}, we explore the use of SHAP explanations in the context of talent identification. Chapters \ref{ch:iaicasestudy} and \ref{ch:spf}  address challenges related to consideration of diversity in TI. In Chapter \ref{ch:iaicasestudy}, we present a participatory design study, which aims to use IAIDSTs to help TI professionals account for diversity. In Chapter \ref{ch:spf} we implement one of the designs from Chapter \ref{ch:iaicasestudy}. Chapter \ref{ch:studentuse} attempts to mitigate the risks of applicant usage of generative AI. It explores the use of generative AI detection tools as DSTs in the context of talent identification. Finally, in Chapter \ref{ch:discussion}, we discuss our design recommendations, note limitations of our approach, and conclude.

\section{Publications}

\begin{itemize}
    \item \textcite{natarajan_trust_2023} Trust Explanations to do What They Say
    \item \textcite{citation needed} `You Trust Me, But Should You?': Misleading Explanations of AI Outputs
\end{itemize}