Artificially Intelligent (AI) systems are being implemented across a variety of fields, including the particularly sensitive field of Talent Identification (TI). With these implementations, existing ethical challenges are exacerbated and new challenges are posed. Many of these challenges centre on Diversity, Equity, and Inclusion (DEI). Here we contend that careful implementation of Interpretable Artificial Intelligence (IAI) and Decision Support Tools (DSTs) can alleviate existing DEI challenges, address new challenges, and improve TI professionals' decision-making.

We first analyse the existing state of AI, IAI, and DSTs, and their applications to TI problems. We define terms related to IAIDSTs and examine preconceptions about what makes specific IAIDSTs well-suited to this purposes. We then look at open DEI challenges in TI, including but not limited to those introduced or exacerbated by the use of AI in TI. Finally, we make a note of other systems designed to solve similar problems in TI.

We move on to examine a series of case studies wherein different types of IAIDSTs are used to address different DEI challenges in TI. In each case, we develop or examine the IAIDST used, note the use cases for which it is sufficient and the potential pitfalls in its implementation. We then demonstrate for a variety of types of IAIDSTs ways in which these systems can solve DEI issues in TI while addressing new complications and improving workflows and decision-making. In this examination, we look both at post-hoc explainable systems and intrinsically interpretable models.

Finally, we draw insights from these case studies and present prescriptions for how and when one might use the IAIDSTs discussed. We extrapolate these insights into more general recommendations for designing and implementing IAIDSTs in TI.
